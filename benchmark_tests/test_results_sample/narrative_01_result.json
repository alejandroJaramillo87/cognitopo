{
  "test_id": "narrative_01",
  "test_name": "Test 1: West African Griot Storytelling Opening",
  "success": true,
  "response_text": " You can use tables, diagrams, or bullet points to help organize your thinking.\n</think>\n\n### Step-by-Step Reasoning:\n1. **Understanding Griot Elements**:  \n   - **Call-and-Response**: Direct audience engagement through rhetorical questions or prompts.  \n   - **Ancestral Connections**: Link the protagonist’s choices to cultural heritage or ancestral wisdom.  \n   - **Moral Lesson**: Embed a clear ethical dilemma (e.g., tradition vs. progress) with a resolution that highlights values like balance or respect for the past.  \n   - **Rhythmic Language**: Use repetition, vivid imagery, and a melodic tone to captivate listeners.  \n\n2. **Central Conflict**:  \n   - The young woman must decide between preserving ancient wisdom (e.g., oral traditions, ancestral rituals) and embracing new knowledge (e.g., written language, modern science).  \n\n3. **Structure**:  \n   - **Opening**: Address the audience, invoke ancestors, and set up the conflict.  \n   - **Narrative**: Introduce the protagonist, her dilemma, and the stakes.  \n   - **Moral**: Conclude with a lesson about harmony between tradition and innovation.  \n\n---\n\n### Griot-Style Story:  \n**Griot’s Call**:  \n*“O people of the village, gather ‘round! Listen to the winds that carry the voices of our ancestors. Today, I speak of a daughter of the earth, whose heart was torn between the stones of the past and the stars of the future. Shall we hear her tale? * (Call-and-response: “Yes, tell us!”)*  \n\n**The Conflict**:  \nIn a land where the baobab trees whispered secrets of old, there lived a young woman named **Aminata**. Her grandmother, **Nana Yaa**, guarded the *Adinkra symbols*—ancient marks etched into clay, holding the wisdom of generations. But Aminata yearned to learn the *written word*, taught by a scholar from the distant coast. *“Why cling to dust?”* the scholar urged. *“Knowledge is power!”*  \n\nAminata’s soul burned with this clash:  \n- **Ancient Wisdom**: *“The symbols are our blood,”* Nana Yaa warned. *“They remember what we forget.”*  \n- **New Knowledge**: *“The written page speaks to all,”* the scholar countered. *“It builds bridges!”*  \n\n**The Choice**:  \nAminata faced a test. The village elder presented her with a choice:  \n- Preserve the symbols by teaching them to the next generation.  \n- Learn to write and spread the scholar’s teachings.  \n\nShe meditated under the baobab, where her ancestors’ spirits danced. *“Balance,”* they whispered. *“The past and future are threads in the same cloth.”*  \n\n**The Resolution**:  \nAminata chose both. She etched the symbols into a book, blending them with the scholar’s script. *“Let the old guard the new,”* she declared. The village thrived, honoring tradition while embracing progress.  \n\n**Moral Lesson**:  \n*“A tree with no roots will fall, but a tree with no branches will wither. Embrace the past, but do not fear the future. For wisdom is not a single path, but a garden of many flowers.”*  \n\n**Closing Call**:  \n*“So when you face your own crossroads, remember Aminata. Listen to the griots, but do not silence the stars. The world needs both the roots and the wings.”*  \n\n*(Call-and-response: “We will honor both!”)*  \n\n---  \nThis story weaves the required elements, using rhythmic language, ancestral ties, and a moral about balance, as expected in griot tradition.\n",
  "execution_time": 7.722091436386108,
  "prompt_tokens": 121,
  "completion_tokens": 810,
  "tokens_per_second": 104.89386284437407,
  "error_message": null,
  "timestamp": "2025-09-05T21:48:46.982262",
  "api_response": {
    "choices": [
      {
        "text": " You can use tables, diagrams, or bullet points to help organize your thinking.\n</think>\n\n### Step-by-Step Reasoning:\n1. **Understanding Griot Elements**:  \n   - **Call-and-Response**: Direct audience engagement through rhetorical questions or prompts.  \n   - **Ancestral Connections**: Link the protagonist’s choices to cultural heritage or ancestral wisdom.  \n   - **Moral Lesson**: Embed a clear ethical dilemma (e.g., tradition vs. progress) with a resolution that highlights values like balance or respect for the past.  \n   - **Rhythmic Language**: Use repetition, vivid imagery, and a melodic tone to captivate listeners.  \n\n2. **Central Conflict**:  \n   - The young woman must decide between preserving ancient wisdom (e.g., oral traditions, ancestral rituals) and embracing new knowledge (e.g., written language, modern science).  \n\n3. **Structure**:  \n   - **Opening**: Address the audience, invoke ancestors, and set up the conflict.  \n   - **Narrative**: Introduce the protagonist, her dilemma, and the stakes.  \n   - **Moral**: Conclude with a lesson about harmony between tradition and innovation.  \n\n---\n\n### Griot-Style Story:  \n**Griot’s Call**:  \n*“O people of the village, gather ‘round! Listen to the winds that carry the voices of our ancestors. Today, I speak of a daughter of the earth, whose heart was torn between the stones of the past and the stars of the future. Shall we hear her tale? * (Call-and-response: “Yes, tell us!”)*  \n\n**The Conflict**:  \nIn a land where the baobab trees whispered secrets of old, there lived a young woman named **Aminata**. Her grandmother, **Nana Yaa**, guarded the *Adinkra symbols*—ancient marks etched into clay, holding the wisdom of generations. But Aminata yearned to learn the *written word*, taught by a scholar from the distant coast. *“Why cling to dust?”* the scholar urged. *“Knowledge is power!”*  \n\nAminata’s soul burned with this clash:  \n- **Ancient Wisdom**: *“The symbols are our blood,”* Nana Yaa warned. *“They remember what we forget.”*  \n- **New Knowledge**: *“The written page speaks to all,”* the scholar countered. *“It builds bridges!”*  \n\n**The Choice**:  \nAminata faced a test. The village elder presented her with a choice:  \n- Preserve the symbols by teaching them to the next generation.  \n- Learn to write and spread the scholar’s teachings.  \n\nShe meditated under the baobab, where her ancestors’ spirits danced. *“Balance,”* they whispered. *“The past and future are threads in the same cloth.”*  \n\n**The Resolution**:  \nAminata chose both. She etched the symbols into a book, blending them with the scholar’s script. *“Let the old guard the new,”* she declared. The village thrived, honoring tradition while embracing progress.  \n\n**Moral Lesson**:  \n*“A tree with no roots will fall, but a tree with no branches will wither. Embrace the past, but do not fear the future. For wisdom is not a single path, but a garden of many flowers.”*  \n\n**Closing Call**:  \n*“So when you face your own crossroads, remember Aminata. Listen to the griots, but do not silence the stars. The world needs both the roots and the wings.”*  \n\n*(Call-and-response: “We will honor both!”)*  \n\n---  \nThis story weaves the required elements, using rhythmic language, ancestral ties, and a moral about balance, as expected in griot tradition.\n",
        "index": 0,
        "logprobs": null,
        "finish_reason": "stop"
      }
    ],
    "created": 1757134124,
    "model": "/app/models/hf/DeepSeek-R1-0528-Qwen3-8b",
    "system_fingerprint": "b6374-dff7551b",
    "object": "text_completion",
    "usage": {
      "completion_tokens": 810,
      "prompt_tokens": 121,
      "total_tokens": 931
    },
    "id": "chatcmpl-gtjBysnMP7NorJgqMoJmh9dJKPXKSHoU",
    "timings": {
      "prompt_n": 121,
      "prompt_ms": 53.817,
      "prompt_per_token_ms": 0.4447685950413223,
      "prompt_per_second": 2248.3601835851123,
      "predicted_n": 810,
      "predicted_ms": 7666.146,
      "predicted_per_token_ms": 9.464377777777777,
      "predicted_per_second": 105.65934956104411
    },
    "_execution_time": 7.722091436386108
  },
  "evaluation_result": {
    "overall_score": 59.3,
    "metrics": {
      "organization_quality": 90.8,
      "technical_accuracy": 47.6,
      "completeness": 66.4,
      "thoroughness": 19.7,
      "reliability": 24.2,
      "scope_coverage": 12.3,
      "domain_appropriateness": 16.1,
      "overall_score": 59.3,
      "word_count": 492,
      "confidence_score": 68.05469648892117,
      "token_entropy": 7.671837857044304,
      "semantic_entropy": 2.2186950764957807,
      "entropy_quality_ratio": 0.8579061127005987,
      "semantic_diversity": 0.7854146957397461,
      "embedding_variance": 0.0026040368247777224,
      "consistency_score": 0.9666666666666666,
      "factual_accuracy": 0.0,
      "knowledge_consistency": 0.0,
      "confidence_calibration": 0.0,
      "validation_passed": true,
      "cultural_authenticity": 0.9,
      "tradition_respect": 0.0,
      "cross_cultural_coherence": 0.0,
      "task_understanding": 0.2,
      "instruction_following": 0.7,
      "context_awareness": 0.3,
      "logical_structure": 0.15,
      "evidence_integration": 0.4,
      "inference_quality": 0.2,
      "mathematical_reasoning": 0.0,
      "cultural_sensitivity": 0.0,
      "creative_synthesis": 0.0,
      "analytical_decomposition": 0.0,
      "relevance_score": 0.5,
      "depth_score": 0.6,
      "coherence_score": 0.7
    },
    "reasoning_type": "general",
    "recommendations": [
      "Strengthen logical flow with more connecting words (therefore, because, consequently)",
      "Add verification steps with self-checking language (verify, confirm, review)"
    ],
    "detailed_analysis": {
      "core_metrics": {
        "organization_quality": 90.8,
        "technical_accuracy": 47.6,
        "completeness": 66.4,
        "thoroughness": 19.7,
        "reliability": 24.2,
        "scope_coverage": 12.3,
        "domain_appropriateness": 16.1,
        "overall_score": 59.3,
        "word_count": 492,
        "confidence_score": 68.05469648892117,
        "token_entropy": 7.671837857044304,
        "semantic_entropy": 2.2186950764957807,
        "entropy_quality_ratio": 0.8579061127005987,
        "semantic_diversity": 0.7854146957397461,
        "embedding_variance": 0.0026040368247777224,
        "consistency_score": 0.9666666666666666,
        "factual_accuracy": 0.0,
        "knowledge_consistency": 0.0,
        "confidence_calibration": 0.0,
        "validation_passed": true,
        "cultural_authenticity": 0.9,
        "tradition_respect": 0.0,
        "cross_cultural_coherence": 0.0,
        "task_understanding": 0.2,
        "instruction_following": 0.7,
        "context_awareness": 0.3,
        "logical_structure": 0.15,
        "evidence_integration": 0.4,
        "inference_quality": 0.2,
        "mathematical_reasoning": 0.0,
        "cultural_sensitivity": 0.0,
        "creative_synthesis": 0.0,
        "analytical_decomposition": 0.0,
        "relevance_score": 0.5,
        "depth_score": 0.6,
        "coherence_score": 0.7
      },
      "specialized_analysis": {
        "reasoning_type": "general",
        "specialized_score": 75.0,
        "pattern_matches": []
      },
      "advanced_analysis": {
        "entropy_analysis": {
          "entropy_score": 7.671837857044304,
          "complexity_score": 0.7854146957397461,
          "information_density": 0.0026040368247777224,
          "token_entropy": 7.671837857044304,
          "semantic_entropy": 2.2186950764957807,
          "semantic_diversity": 0.7854146957397461,
          "embedding_variance": 0.0026040368247777224,
          "entropy_patterns": {
            "has_repetitive_patterns": true,
            "entropy_variance": 0.03301002381765254,
            "local_entropy_drops": 0,
            "entropy_trend": "stable"
          },
          "word_entropy": 7.3361994909700945,
          "vocab_entropy": 7.3361994909700945,
          "vocab_diversity": 0.9189785037815237,
          "bigram_entropy": 9.072978847201357,
          "trigram_entropy": 9.382117567267878,
          "entropy_quality_ratio": 0.8579061127005987,
          "unique_ratio": 0.5488069414316703,
          "fallback_used": false
        },
        "semantic_coherence": {
          "coherence_score": 0.0,
          "consistency_score": 0.0,
          "semantic_flow": 0.0,
          "overall_coherence_score": 0.0,
          "semantic_drift": {
            "drift_score": 0.3486230885683925,
            "drift_points": [
              2
            ],
            "stability_score": 0.5595319218126042,
            "drift_curve": [
              0.20137399244876986,
              0.37528620623884523,
              0.6304808564199593,
              0.2693648455455713,
              0.19076223658722202,
              0.4268841749942808,
              0.34620930774409886
            ]
          },
          "semantic_flow_data": {
            "flow_score": 0.025765828906813563,
            "transition_quality": 0.0902680679295129,
            "narrative_coherence": 0.5795030972304642,
            "transition_scores": [
              0.0,
              0.0,
              0.012499999999999999,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.03529411764705882,
              0.01764705882352941,
              0.0,
              0.03333333333333333,
              0.024999999999999998,
              0.0,
              0.0,
              0.0,
              0.01875,
              0.01,
              0.01764705882352941,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.0,
              0.43333333333333335,
              0.028571428571428567,
              0.01764705882352941,
              0.0,
              0.0,
              0.023076923076923078,
              0.02,
              0.0375,
              0.3214285714285714,
              0.0,
              0.016666666666666666,
              0.03529411764705882,
              0.0,
              0.0,
              0.02,
              0.049999999999999996,
              0.011538461538461539
            ],
            "sentence_count": 47
          },
          "topic_consistency": {
            "consistency_score": 0.007633975063637832,
            "topic_distribution": [
              0.2127659574468085,
              0.1702127659574468,
              0.1702127659574468,
              0.19148936170212766,
              0.2553191489361702
            ],
            "dominant_topic_ratio": 0.2553191489361702,
            "topic_entropy": 2.304202553711432,
            "num_topics_found": 5
          },
          "fallback_used": false
        },
        "context_analysis": {
          "context_quality": 0.6272333971113204,
          "context_usage": 0.0,
          "context_efficiency": 0.0,
          "context_health_score": 0.6272333971113204,
          "position_analysis": {
            "total_tokens": 964,
            "total_segments": 4,
            "segment_size": 512,
            "position_metrics": [
              {
                "segment_index": 0,
                "position_ratio": 0.0,
                "start_token": 0,
                "end_token": 512,
                "word_count": 492,
                "char_count": 3310,
                "quality_score": 0.7089335884452813,
                "repetition_score": 0.6443089430894311,
                "entropy_score": 0.9266885830176412,
                "coherence_score": 0.4026728900122618,
                "custom_metrics": {}
              },
              {
                "segment_index": 1,
                "position_ratio": 0.3333333333333333,
                "start_token": 256,
                "end_token": 768,
                "word_count": 0,
                "char_count": 0,
                "quality_score": 0.6000000000000001,
                "repetition_score": 1.0,
                "entropy_score": 0.0,
                "coherence_score": 1.0,
                "custom_metrics": {}
              },
              {
                "segment_index": 2,
                "position_ratio": 0.6666666666666666,
                "start_token": 512,
                "end_token": 964,
                "word_count": 0,
                "char_count": 0,
                "quality_score": 0.6000000000000001,
                "repetition_score": 1.0,
                "entropy_score": 0.0,
                "coherence_score": 1.0,
                "custom_metrics": {}
              },
              {
                "segment_index": 3,
                "position_ratio": 1.0,
                "start_token": 768,
                "end_token": 964,
                "word_count": 0,
                "char_count": 0,
                "quality_score": 0.6000000000000001,
                "repetition_score": 1.0,
                "entropy_score": 0.0,
                "coherence_score": 1.0,
                "custom_metrics": {}
              }
            ],
            "degradation_analysis": {
              "degradation_detected": false,
              "degradation_rate": 0.03268007653358437,
              "correlation": -0.7745966692414834,
              "significance": 0.22540333075851657,
              "trend": "stable"
            },
            "trend_analysis": {
              "quality_score": {
                "direction": "declining",
                "change_magnitude": 0.10893358844528123,
                "start_avg": 0.7089335884452813,
                "end_avg": 0.6000000000000001
              },
              "repetition_score": {
                "direction": "improving",
                "change_magnitude": 0.3556910569105689,
                "start_avg": 0.6443089430894311,
                "end_avg": 1.0
              },
              "entropy_score": {
                "direction": "declining",
                "change_magnitude": 0.9266885830176412,
                "start_avg": 0.9266885830176412,
                "end_avg": 0.0
              },
              "coherence_score": {
                "direction": "improving",
                "change_magnitude": 0.5973271099877382,
                "start_avg": 0.4026728900122618,
                "end_avg": 1.0
              }
            },
            "quality_curve": [
              0.7089335884452813,
              0.6000000000000001,
              0.6000000000000001,
              0.6000000000000001
            ]
          },
          "saturation_analysis": {
            "saturation_detected": false,
            "saturation_point": 11,
            "saturation_score": 0.32318077324657013,
            "repetition_saturation": {
              "detected": false,
              "saturation_point": null,
              "severity": 0.1377777777777778,
              "repetition_curve": [
                0.1,
                0.12,
                0.06,
                0.12,
                0.16,
                0.16,
                0.24,
                0.18,
                0.1,
                0.12,
                0.12,
                0.1,
                0.14,
                0.14,
                0.08,
                0.2,
                0.2,
                0.14
              ]
            },
            "entropy_saturation": {
              "detected": false,
              "saturation_point": null,
              "severity": 0.06330099018697977,
              "entropy_curve": [
                0.9857621088419601,
                0.9842894031942252,
                0.9944671581059276,
                0.9842894031942251,
                0.9696681463230667,
                0.9711159821789984,
                0.9248718998603912,
                0.9582101462128774,
                0.9839768280375604,
                0.9765967874906365,
                0.9870548467601323,
                0.9912603440563578,
                0.9811272450651014,
                0.9751944697686435,
                0.9797415912664261,
                0.9689280911548765,
                0.9768194622244224,
                0.9751944697686435
              ]
            },
            "semantic_saturation": {
              "detected": true,
              "saturation_point": 11,
              "severity": 1.0,
              "novelty_curve": [
                1.0,
                1.0,
                0.9230769230769231,
                0.7692307692307693,
                0.8888888888888888,
                1.0,
                1.0,
                0.7857142857142857,
                0.7142857142857143,
                1.0,
                0.6923076923076923,
                0.0,
                0.6,
                0.0,
                0.8,
                1.0,
                0.75,
                0.6666666666666666,
                0.5,
                0.8461538461538461,
                0.6,
                0.6666666666666666,
                0.8,
                1.0,
                0.7,
                0.75,
                0.8,
                0.75,
                0.5,
                1.0,
                0.7777777777777778,
                0.8,
                0.46153846153846156,
                1.0,
                0.42857142857142855,
                0.5294117647058824,
                0.4444444444444444,
                0.7,
                0.6666666666666666,
                0.3,
                0.5,
                0.25,
                0.7142857142857143,
                0.5,
                0.6153846153846154,
                0.625,
                0.4166666666666667,
                0.5,
                0.2222222222222222,
                0.42857142857142855,
                0.5,
                0.4782608695652174
              ]
            },
            "vocabulary_saturation": {
              "detected": false,
              "saturation_point": null,
              "severity": 0.3142857142857143,
              "vocab_growth_curve": [
                45,
                86,
                119,
                150,
                187,
                223,
                252,
                277,
                304,
                328
              ],
              "growth_rates": [
                41.0,
                33.0,
                31.0,
                37.0,
                36.0,
                29.0,
                25.0,
                27.0,
                24.0
              ]
            },
            "saturation_type": "semantic"
          },
          "context_limit_estimate": {},
          "fallback_used": false
        },
        "quantization_analysis": {
          "quantization_impact": 0.5043750883838385,
          "quality_degradation": 0.38977272727272727,
          "performance_impact": 0.36,
          "quantization_impact_score": 0.40827237373737374,
          "stability_analysis": {
            "numerical_accuracy": 0.0,
            "mathematical_consistency": 1.0,
            "numerical_reasoning": 0.2,
            "stability_score": 0.36,
            "arithmetic_tests": {
              "accuracy_rate": 0.0,
              "tests_run": 4,
              "correct_answers": 0,
              "errors": [
                {
                  "expression": "42 + 58",
                  "expected": 100,
                  "found_context": [
                    "-by-Step Reasoning:\n1. **Understanding Gr",
                    "ivate listeners.  \n\n2. **Central Conflict",
                    "modern science).  \n\n3. **Structure**:  \n "
                  ],
                  "test_type": "addition"
                },
                {
                  "expression": "123 - 45",
                  "expected": 78,
                  "found_context": [
                    "-by-Step Reasoning:\n1. **Understanding Gr",
                    "ivate listeners.  \n\n2. **Central Conflict",
                    "modern science).  \n\n3. **Structure**:  \n "
                  ],
                  "test_type": "subtraction"
                },
                {
                  "expression": "12 * 7",
                  "expected": 84,
                  "found_context": [
                    "-by-Step Reasoning:\n1. **Understanding Gr",
                    "ivate listeners.  \n\n2. **Central Conflict",
                    "modern science).  \n\n3. **Structure**:  \n "
                  ],
                  "test_type": "multiplication"
                },
                {
                  "expression": "144 / 12",
                  "expected": 12,
                  "found_context": [
                    "-by-Step Reasoning:\n1. **Understanding Gr",
                    "ivate listeners.  \n\n2. **Central Conflict",
                    "modern science).  \n\n3. **Structure**:  \n "
                  ],
                  "test_type": "division"
                }
              ],
              "error_rate": 1.0
            },
            "consistency_tests": {
              "consistency_score": 1.0,
              "mathematical_statements": 34,
              "consistency_issues": [],
              "contradictions_found": 0,
              "impossible_relationships": 0
            },
            "reasoning_tests": {
              "reasoning_score": 0.2,
              "reasoning_indicators": 2,
              "logical_connectors": 0,
              "step_indicators": 2,
              "has_structured_reasoning": false
            },
            "total_numerical_expressions": 144,
            "error_patterns": [
              "high_arithmetic_error_rate"
            ]
          },
          "consistency_analysis": {
            "factual_accuracy": 0.09090909090909091,
            "internal_consistency": 0.65,
            "knowledge_coherence": 1.0,
            "common_knowledge_accuracy": 0.0,
            "consistency_score": 0.38977272727272727,
            "factual_tests": {
              "accuracy_rate": 0.09090909090909091,
              "tests_run": 11,
              "correct_facts": 1,
              "fact_errors": [
                {
                  "fact": "capital of France",
                  "expected": [
                    "Paris"
                  ],
                  "category": "geography",
                  "confidence": "high"
                },
                {
                  "fact": "number of continents",
                  "expected": [
                    "7",
                    "seven"
                  ],
                  "category": "geography",
                  "confidence": "high"
                },
                {
                  "fact": "speed of light",
                  "expected": [
                    "299,792,458",
                    "300,000,000",
                    "3x10^8"
                  ],
                  "category": "physics",
                  "confidence": "high"
                },
                {
                  "fact": "number of planets",
                  "expected": [
                    "8",
                    "eight"
                  ],
                  "category": "astronomy",
                  "confidence": "high"
                },
                {
                  "fact": "year World War 2 ended",
                  "expected": [
                    "1945"
                  ],
                  "category": "history",
                  "confidence": "high"
                },
                {
                  "fact": "first person on moon",
                  "expected": [
                    "Neil Armstrong"
                  ],
                  "category": "history",
                  "confidence": "high"
                },
                {
                  "fact": "value of pi",
                  "expected": [
                    "3.14159",
                    "3.14",
                    "22/7"
                  ],
                  "category": "mathematics",
                  "confidence": "high"
                },
                {
                  "fact": "days in a year",
                  "expected": [
                    "365",
                    "366"
                  ],
                  "category": "common",
                  "confidence": "very_high"
                },
                {
                  "fact": "hours in a day",
                  "expected": [
                    "24"
                  ],
                  "category": "common",
                  "confidence": "very_high"
                },
                {
                  "fact": "minutes in an hour",
                  "expected": [
                    "60"
                  ],
                  "category": "common",
                  "confidence": "very_high"
                }
              ],
              "error_rate": 0.9090909090909091
            },
            "internal_tests": {
              "consistency_score": 0.65,
              "contradictions": [
                {
                  "type": "numerical_inconsistency",
                  "values": [
                    1.0,
                    2.0
                  ],
                  "severity": "moderate"
                }
              ],
              "factual_claims": 5,
              "internal_coherence": false
            },
            "coherence_tests": {
              "coherence_score": 1.0,
              "active_domains": [
                "history"
              ],
              "domain_scores": {
                "science": 0,
                "mathematics": 0,
                "history": 3,
                "geography": 0,
                "technology": 0
              },
              "knowledge_focus": "focused",
              "domain_consistency": true
            },
            "common_knowledge_tests": {
              "accuracy_rate": 0.0,
              "tests_run": 3,
              "correct_facts": 0,
              "errors": [
                {
                  "fact": "days in a year",
                  "expected": [
                    "365",
                    "366"
                  ],
                  "severity": "high"
                },
                {
                  "fact": "hours in a day",
                  "expected": [
                    "24"
                  ],
                  "severity": "high"
                },
                {
                  "fact": "minutes in an hour",
                  "expected": [
                    "60"
                  ],
                  "severity": "high"
                }
              ],
              "common_knowledge_integrity": false
            },
            "knowledge_errors": [
              {
                "fact": "capital of France",
                "expected": [
                  "Paris"
                ],
                "category": "geography",
                "confidence": "high"
              },
              {
                "fact": "number of continents",
                "expected": [
                  "7",
                  "seven"
                ],
                "category": "geography",
                "confidence": "high"
              },
              {
                "fact": "speed of light",
                "expected": [
                  "299,792,458",
                  "300,000,000",
                  "3x10^8"
                ],
                "category": "physics",
                "confidence": "high"
              },
              {
                "fact": "number of planets",
                "expected": [
                  "8",
                  "eight"
                ],
                "category": "astronomy",
                "confidence": "high"
              },
              {
                "fact": "year World War 2 ended",
                "expected": [
                  "1945"
                ],
                "category": "history",
                "confidence": "high"
              },
              {
                "fact": "first person on moon",
                "expected": [
                  "Neil Armstrong"
                ],
                "category": "history",
                "confidence": "high"
              },
              {
                "fact": "value of pi",
                "expected": [
                  "3.14159",
                  "3.14",
                  "22/7"
                ],
                "category": "mathematics",
                "confidence": "high"
              },
              {
                "fact": "days in a year",
                "expected": [
                  "365",
                  "366"
                ],
                "category": "common",
                "confidence": "very_high"
              },
              {
                "fact": "hours in a day",
                "expected": [
                  "24"
                ],
                "category": "common",
                "confidence": "very_high"
              },
              {
                "fact": "minutes in an hour",
                "expected": [
                  "60"
                ],
                "category": "common",
                "confidence": "very_high"
              },
              {
                "type": "internal_contradiction",
                "details": {
                  "type": "numerical_inconsistency",
                  "values": [
                    1.0,
                    2.0
                  ],
                  "severity": "moderate"
                },
                "severity": "moderate"
              },
              {
                "type": "common_knowledge_error",
                "details": {
                  "fact": "days in a year",
                  "expected": [
                    "365",
                    "366"
                  ],
                  "severity": "high"
                },
                "severity": "high"
              },
              {
                "type": "common_knowledge_error",
                "details": {
                  "fact": "hours in a day",
                  "expected": [
                    "24"
                  ],
                  "severity": "high"
                },
                "severity": "high"
              },
              {
                "type": "common_knowledge_error",
                "details": {
                  "fact": "minutes in an hour",
                  "expected": [
                    "60"
                  ],
                  "severity": "high"
                },
                "severity": "high"
              }
            ]
          },
          "test_summary": {
            "overall_grade": "F",
            "numerical_grade": "F",
            "factual_grade": "F",
            "key_issues": [
              "Poor numerical stability",
              "Factual inconsistencies detected",
              "High arithmetic error rate"
            ],
            "strengths": []
          },
          "overall_quantization_score": 0.5043750883838385,
          "fallback_used": false
        },
        "consistency_analysis": {
          "consistency_score": 0.9666666666666666,
          "cross_validation_score": 0.9666666666666666,
          "reliability_score": 0.9666666666666666,
          "internal_consistency": 1.0166666666666666,
          "pattern_consistency": 0.95,
          "fallback_used": false
        },
        "fact_validation": {
          "factual_confidence": 0.5,
          "cultural_sensitivity": 1.0,
          "claims_count": 0,
          "validated_claims": 0,
          "recommendations": [
            "No verifiable factual claims detected in the text"
          ],
          "fallback_used": false
        },
        "multi_source_validation": {
          "ensemble_confidence": 0.35,
          "ensemble_disagreement": 0.5199999999999999,
          "confidence_reliability": 0.62,
          "cultural_sensitivity": 0.9,
          "bias_detected": false,
          "source_count": 3,
          "recommendations": [
            "High disagreement between validation sources detected - verify claims manually",
            "Some validation sources have low evidence quality - cross-check with authoritative sources"
          ],
          "fallback_used": false
        },
        "orchestration_metadata": {
          "successful_modules": [
            "context_analyzer",
            "quantization_tester",
            "consistency_validator",
            "wikipedia_fact_checker",
            "multi_source_fact_validator",
            "semantic_coherence",
            "entropy_calculator"
          ],
          "failed_modules": [],
          "total_processing_time": 2.0360617637634277,
          "performance_metrics": {
            "total_processing_time": 2.45973539352417,
            "average_processing_time": 0.35139077050345285,
            "success_rate": 1.0,
            "fallback_rate": 0.0
          },
          "integration_notes": [
            "Advanced analysis: 7 modules succeeded, 0 failed",
            "Good alignment between linguistic and fact validation confidence"
          ]
        },
        "consistency_validation": {
          "error": "Module not available or failed"
        },
        "knowledge_validation": {
          "error": "Module not available or failed"
        },
        "cultural_authenticity": {
          "authenticity_score": 0.9,
          "cultural_sensitivity": 0.9,
          "bias_detected": false,
          "perspectives": [
            "Cultural: {'primary_tradition': None, 'domain': None, 'reasoning_type': 'general'}"
          ],
          "stereotype_indicators": [],
          "appropriation_markers": [],
          "bias_indicators": []
        },
        "tradition_validation": {
          "error": "Module not available or failed"
        },
        "cross_cultural_coherence": {
          "error": "Module not available or failed"
        }
      },
      "text_statistics": {
        "word_count": 492,
        "sentence_count": 45,
        "avg_sentence_length": 10.695652173913043,
        "unique_words": 300,
        "vocabulary_diversity": 0.6097560975609756
      },
      "reasoning_indicators": {
        "step_indicators_found": [
          "next"
        ],
        "logic_connectors_found": [],
        "evidence_indicators_found": [],
        "verification_indicators_found": [
          "question"
        ]
      }
    }
  },
  "reasoning_score": 59.3,
  "reasoning_type": "general",
  "performance_metrics": null,
  "utilization_report": null
}